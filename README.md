<div align="center">

# Synergizing Motion and Appearance: Multi-Scale Compensatory Codebooks for Talking Head Video Generation

Shuling Zhao<sup>1</sup> &emsp; [Fa-Ting Hong](https://harlanhong.github.io/)<sup>1</sup> &emsp; [Xiaoshui Huang](https://xiaoshuihuang.github.io/)<sup>2</sup> &emsp; [Dan Xu](https://www.danxurgb.net/)<sup>1</sup>

<sup>1</sup>The Hong Kong University of Science and Technology <br>
<sup>2</sup>Shanghai Jiao Tong University

<!-- <a href='https://arxiv.org/abs/2403.11641'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a> -->
<a href=''><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>


<!--<img src='assets/teaser.gif'>-->
<img src="assets/sota_qualitative_min.png" width="800px"/>


### Cross-identity Reenactment Results
<img src="assets/video1.gif" width="400px"/> <img src="assets/video3.gif" width="400px"/>
<img src="assets/video2.gif" width="400px"/> <img src="assets/video4.gif" width="400px"/>


### More Generalization Results
<img src="assets/generalization_result.gif"  width="800px"/>
<img src="assets/generalization_result_1.gif"  width="800px"/>
<img src="assets/generalization_result_2.gif"  width="800px"/>
</div>

## Updates
- **`2024/10/21`**: We created this repo.

## Acknowledgements
Our implementation is based on [FOMM](https://github.com/AliaksandrSiarohin/first-order-model) and [CodeFormer](https://github.com/sczhou/CodeFormer). We appreciate their great works.

## Citation

## Contact
If you have any question or collaboration needs, please email `szhaoax@connect.ust.hk`.

