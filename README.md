<div align="center">

# Synergizing Motion and Appearance: Multi-Scale Compensatory Codebooks for Talking Head Video Generation

Shuling Zhao<sup>1</sup> &emsp; [Fa-Ting Hong](https://harlanhong.github.io/)<sup>1</sup> &emsp; [Xiaoshui Huang](https://xiaoshuihuang.github.io/)<sup>2</sup> &emsp; [Dan Xu](https://www.danxurgb.net/)<sup>1</sup>

<sup>1</sup>The Hong Kong University of Science and Technology <br>
<sup>2</sup>Shanghai Jiao Tong University

<!-- <a href='https://arxiv.org/abs/2403.11641'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a> -->
</div>

<!--<img src='assets/teaser.gif'>-->
<img src="assets/sota_qualitative-min.png">

## Updates
- **`2024/10/21`**: We created this repo.

## Acknowledgements
Our implementation is based on [FOMM](https://github.com/AliaksandrSiarohin/first-order-model) and [CodeFormer](https://github.com/sczhou/CodeFormer). We appreciate their great works.

## Citation

